{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import time\n",
    "import math\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimePredictionModel:\n",
    "    # Types of abstractions that can be used to build the model\n",
    "    SEQUENCE_ABSTRACTION = 0\n",
    "    SET_ABSTRACTION = 1\n",
    "    MULTISET_ABSTRACTION = 2\n",
    "\n",
    "    def __init__(self, cases=[], abstraction=SEQUENCE_ABSTRACTION, horizon=0, calendar=None):\n",
    "        self.abstraction = abstraction\n",
    "        # Unlimited horizon is applied if this parameter is set to 0\n",
    "        self.horizon = horizon\n",
    "        self.calendar = calendar\n",
    "        self.states = dict()\n",
    "        self.initialstate = self.addState([])\n",
    "        self.build(cases)\n",
    "\n",
    "    def addState(self, trace):\n",
    "        state = self.codeState(trace)\n",
    "        if state not in self.states:\n",
    "            self.states[state] = []\n",
    "        return state\n",
    "\n",
    "    def codeState(self, trace):\n",
    "        if self.abstraction == self.SEQUENCE_ABSTRACTION:\n",
    "            # Sequence of execution matters\n",
    "            state = tuple(trace)\n",
    "        elif self.abstraction == self.SET_ABSTRACTION:\n",
    "            # Sequence and repetitions do not matter\n",
    "            state = frozenset(trace)\n",
    "        elif self.abstraction == self.MULTISET_ABSTRACTION:\n",
    "            # Sequence does not matter, but repetions do\n",
    "            state = tuple(sorted(Counter(trace).items()))\n",
    "        else:\n",
    "            raise ValueError(\"Invalid abstraction type.\")\n",
    "        return state\n",
    "\n",
    "    def build(self, cases):\n",
    "        for case in cases:\n",
    "            self.processCase(case)\n",
    "\n",
    "    def processCase(self, case):\n",
    "        activities, eventtimes = zip(*case)\n",
    "        #print(\"Case activities:\", activities)\n",
    "        for i in range(len(case)):\n",
    "            # t is the time the state is visited; e is the elapsed time since the start\n",
    "            # of the case; r is the remaining flow time; s is the sojourn time, i.e., the\n",
    "            # time until the next event\n",
    "            t = time.mktime(eventtimes[i])\n",
    "            e = self.elapsedTime(eventtimes[0], eventtimes[i])\n",
    "            r = self.elapsedTime(eventtimes[i], eventtimes[-1])\n",
    "            if i < len(case) - 1:\n",
    "                s = self.elapsedTime(eventtimes[i], eventtimes[i+1])\n",
    "            else:\n",
    "                s = -1\n",
    "            initial = 0\n",
    "            if self.horizon > 0 and i >= self.horizon:\n",
    "                # Use a limited horizon, i.e., consider the k lasts activities executed\n",
    "                # (k is the value set to self.horizon)\n",
    "                initial = i - self.horizon + 1\n",
    "            for j in range(initial, i+1):\n",
    "                state = self.addState(activities[j:i+1])\n",
    "                #print(\"State:\", state)\n",
    "                self.states[state].append((t, e, r, s))\n",
    "                #print(\"Annotations:\", self.states[state])\n",
    "\n",
    "    def elapsedTime(self, starttime, endtime):\n",
    "        # TODO: Use calendar\n",
    "        start = time.mktime(starttime)\n",
    "        end = time.mktime(endtime)\n",
    "        return end - start\n",
    "\n",
    "    def timePredictionFunction(self, measurements):\n",
    "        mean = np.mean(measurements)\n",
    "        std = np.std(measurements)\n",
    "        min = np.min(measurements)\n",
    "        max = np.max(measurements)\n",
    "        return mean, std, min, max\n",
    "\n",
    "    def predictRemainingTime(self, partialtrace):\n",
    "        #print(\"Predicting remaining time for partial trace\", partialtrace)\n",
    "        initial = 0\n",
    "        if self.horizon > 0 and len(partialtrace) > self.horizon:\n",
    "            initial = len(partialtrace) - self.horizon\n",
    "            #print(\"Initial:\", initial)\n",
    "        while initial < len(partialtrace):\n",
    "            state = self.codeState(partialtrace[initial:])\n",
    "            if state in self.states:\n",
    "                #print(\"State:\", state)\n",
    "                t, e, r, s = zip(*self.states[state])\n",
    "                predicted = self.timePredictionFunction(r)\n",
    "                #print(\"Predicted:\", predicted)\n",
    "                return predicted\n",
    "            initial += 1\n",
    "        # This will only happen if the partial trace contains an activity that did not\n",
    "        # appear in the training set\n",
    "        return self.fallThrough()\n",
    "\n",
    "    def fallThrough(self):\n",
    "        # Could not find any match in te model for the given trace, so use all\n",
    "        # measures stored for states composed of a single activity\n",
    "        allRemaining = []\n",
    "        for state, annotations in self.states.items():\n",
    "            if self.abstraction == self.MULTISET_ABSTRACTION:\n",
    "                state = list(state.elements())\n",
    "            if len(state) == 1:\n",
    "                t, e, r, s = zip(*annotations)\n",
    "                allRemaining.extend(r)\n",
    "        if len(allRemaining) > 0:\n",
    "            predicted = self.timePredictionFunction(allRemaining)\n",
    "            return predicted\n",
    "        else:\n",
    "            # This will only happen if the model is empty (no case has been processed)\n",
    "            print(\"Partial trace does not fit any state in the model. Cannot predict.\")\n",
    "            return None, None, None, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadCases(logname, columns, timeformat):\n",
    "    global df_eventlog\n",
    "    df_eventlog = pd.read_csv(\"../../dataset/test/%s\" % logname, sep=\"|\", error_bad_lines=False)\n",
    "    \n",
    "    csv_data = df_eventlog.values\n",
    "    cases = []\n",
    "    previouscase = None\n",
    "    category = None\n",
    "    case = []\n",
    "    # Columns are (CaseId, ActivityId, CompleteTimestamp)\n",
    "    for row in csv_data:\n",
    "        # Assume events are ordered by CaseID and then CompleteTimestamp in the event log\n",
    "        if row[columns[0]] != previouscase:\n",
    "            if len(case) > 0:\n",
    "                # This is the first event for a new case\n",
    "                cases.append((previouscase, category, case))\n",
    "                case = []\n",
    "            previouscase = row[columns[0]]\n",
    "            if len(columns) > 3:\n",
    "                size = len(columns)\n",
    "                c = \"\"\n",
    "                for i in row[3:size]: c = c + str(i)\n",
    "                category = c\n",
    "        eventtime = time.strptime(row[columns[2]], timeformat)\n",
    "        case.append((row[columns[1]], eventtime))\n",
    "    # Add the last case\n",
    "    cases.append((previouscase, category, case))\n",
    "    return cases\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitIntoCategories(cases):\n",
    "    casesets = dict()\n",
    "    for caseid, category, case in cases:\n",
    "        if category not in casesets:\n",
    "            casesets[category] = [(caseid, case)]\n",
    "        else:\n",
    "            casesets[category].append((caseid, case))\n",
    "    return casesets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runTimePredictions(cases, category, eventlog, directory, h):\n",
    "    global df_eventlog\n",
    "    # Divide the data set into folds for model generation and prediction\n",
    "    foldsize = int(round(len(cases)/3))\n",
    "    trainingset = cases[:2*foldsize]\n",
    "    testset = cases[2*foldsize:]\n",
    "    \n",
    "    avg_mae = 0\n",
    "    avg_gt = 0\n",
    "    \n",
    "    categories_names = \"\"\n",
    "    for cont,i in enumerate(category):\n",
    "        cat = df_eventlog.columns[3+cont]\n",
    "        categories_names = categories_names + (str(cat+'-'+i+'_'))\n",
    "        \n",
    "    eventlog = (\"cat%s_\" % categories_names) + eventlog\n",
    "    \n",
    "    # Build the model\n",
    "    caseids, trainingset = zip(*trainingset)\n",
    "    model = TimePredictionModel(trainingset, abstraction=TimePredictionModel.SEQUENCE_ABSTRACTION, horizon = h)\n",
    "    \n",
    "    columns = [\"CaseID\", \"Prefix length\", \"RT ground truth\", \"Predicted RT\", \"Std Deviation\", \"MAE\", \"MAE Days\"]\n",
    "    \n",
    "    df_prediction_results = pd.DataFrame(index=None, columns=columns)\n",
    "    \n",
    "    casestotest = True\n",
    "    prefixlength = 2\n",
    "    df_prediction_results = pd.DataFrame(columns=columns)\n",
    "    \n",
    "    while casestotest:\n",
    "        print(\"Predicting remaining time using prefix length\", prefixlength)\n",
    "        casestotest = False\n",
    "        for caseid, case in testset:\n",
    "            if len(case) > prefixlength:\n",
    "                activities, eventtimes = zip(*case)\n",
    "                #print(\"Predicting remaining time for case\", caseid)\n",
    "                predicted, std, min, max = model.predictRemainingTime(activities[:prefixlength])\n",
    "                groundtruth = model.elapsedTime(eventtimes[prefixlength-1], eventtimes[-1])\n",
    "                if predicted is not None:\n",
    "                    mae = abs(predicted - groundtruth)\n",
    "                    mae_days = round(mae/86400, 4)\n",
    "                else:\n",
    "                    mae = None\n",
    "                newline = {\"CaseID\": caseid, \"Prefix length\": prefixlength, \"RT ground truth\": groundtruth, \"Predicted RT\": predicted, \"Std Deviation\": std, \"MAE\": mae, \"MAE Days\": mae_days}\n",
    "                df_prediction_results = df_prediction_results.append(newline, ignore_index=True)\n",
    "                casestotest = True\n",
    "        prefixlength += 1\n",
    "    \n",
    "    avg_mae = round(df_prediction_results['MAE'].mean(), 4)\n",
    "    avg_gt = round(df_prediction_results['RT ground truth'].mean(), 4)\n",
    "    \n",
    "    if math.isnan(avg_mae):\n",
    "        avg_mae = 0.0\n",
    "    if math.isnan(avg_gt):\n",
    "        avg_gt = 0.0\n",
    "    \n",
    "    calcPercDataCat(category, avg_mae, avg_gt)\n",
    "    df_prediction_results.to_csv('../../results/'+directory+'/horizon_'+str(horizon)+'/predictions_%s' % eventlog, index=False, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates the percentage of data in the full dataset which belongs to the given categories\n",
    "def calcPercDataCat(categories, mae_mean, ground_truth):\n",
    "    global df_eventlog\n",
    "    global cases_cat\n",
    "    \n",
    "    data_size = df_eventlog.shape[0]\n",
    "    \n",
    "    df_data_per_cat = df_eventlog\n",
    "    \n",
    "    cat_name = \"\"\n",
    "    for cont, i in enumerate(categories):\n",
    "        category = df_eventlog.columns[3+cont]\n",
    "        df_data_per_cat = df_data_per_cat.loc[df_data_per_cat[category] == int(i)]\n",
    "        cat_name = cat_name + (str(category+'='+i+' '))\n",
    "    \n",
    "    perc_cats_full_data = round(df_data_per_cat.shape[0] * 100 / data_size, 2)\n",
    "    cases_cat[cat_name] = [perc_cats_full_data, ground_truth, mae_mean, df_data_per_cat.shape[0]]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the metrics to the running prediction\n",
    "def calcMetrics(cases_cat, directory, horizon):\n",
    "    avgMAE = 0.0\n",
    "    avgGT = 0.0\n",
    "    \n",
    "    f = open(\"../../results/\"+directory+\"/horizon_\"+str(horizon)+\"/metrics.txt\",\"a+\")\n",
    "    \n",
    "    f.write(\"Horizon:%d\" % horizon)\n",
    "    \n",
    "    for i in cases_cat:\n",
    "        f.write(\"\\n\\nCategory: %s\" % i)\n",
    "        f.write(\"\\n  Ground Truth:%.4f\" % cases_cat[i][1])\n",
    "        f.write(\"\\n  Mean for MAE:%.4f\" % cases_cat[i][2])\n",
    "        f.write(\"\\n  Percentage from the full data: %.3f\" % cases_cat[i][0])\n",
    "        f.write(\"\\n  Total cases:%d\" % cases_cat[i][3])  \n",
    "        avgMAE = avgMAE + (cases_cat[i][0] * cases_cat[i][2])\n",
    "        avgGT = avgGT  + (cases_cat[i][0] * cases_cat[i][1])\n",
    "        \n",
    "    avgMAE = avgMAE / 100\n",
    "    avgGT = avgGT / 100\n",
    "    f.write(\"\\n\\nComputed Weighted arithmetic mean for MAE error:\")\n",
    "    f.write(\"\\nTotal Ground Truth:%.4f\" % avgGT)\n",
    "    f.write(\"\\nTotal MAE: %.4f\" % avgMAE)\n",
    "    f.write(\"\\nTotal MAE in days: %.4f\" % (avgMAE/86400))\n",
    "    f.write(\"\\n ------------------------ \\n\\n\")\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting remaining time for case category 0\n",
      "Predicting remaining time using prefix length 2\n",
      "Predicting remaining time using prefix length 3\n",
      "Predicting remaining time using prefix length 4\n",
      "Predicting remaining time using prefix length 5\n",
      "Predicting remaining time using prefix length 6\n",
      "Predicting remaining time using prefix length 7\n",
      "Predicting remaining time using prefix length 8\n",
      "Predicting remaining time using prefix length 9\n",
      "Predicting remaining time using prefix length 10\n",
      "Predicting remaining time using prefix length 11\n",
      "Predicting remaining time using prefix length 12\n",
      "Predicting remaining time using prefix length 13\n",
      "Predicting remaining time using prefix length 14\n",
      "Predicting remaining time using prefix length 15\n",
      "Predicting remaining time using prefix length 16\n",
      "Predicting remaining time using prefix length 17\n",
      "Predicting remaining time using prefix length 18\n",
      "Predicting remaining time using prefix length 19\n",
      "Predicting remaining time using prefix length 20\n",
      "Predicting remaining time using prefix length 21\n",
      "Predicting remaining time using prefix length 22\n",
      "Predicting remaining time using prefix length 23\n",
      "Predicting remaining time using prefix length 24\n",
      "Predicting remaining time using prefix length 25\n",
      "Predicting remaining time using prefix length 26\n",
      "Predicting remaining time using prefix length 27\n",
      "Predicting remaining time using prefix length 28\n",
      "Predicting remaining time for case category 1\n",
      "Predicting remaining time using prefix length 2\n",
      "Predicting remaining time using prefix length 3\n",
      "Predicting remaining time using prefix length 4\n",
      "Predicting remaining time using prefix length 5\n",
      "Predicting remaining time using prefix length 6\n",
      "Predicting remaining time using prefix length 7\n",
      "Predicting remaining time using prefix length 8\n",
      "Predicting remaining time using prefix length 9\n",
      "Predicting remaining time using prefix length 10\n",
      "Predicting remaining time using prefix length 11\n",
      "Predicting remaining time using prefix length 12\n",
      "Predicting remaining time using prefix length 13\n",
      "\n",
      "Computing metrics from prediction\n",
      "\n",
      "Metrics computed\n"
     ]
    }
   ],
   "source": [
    "df_eventlog = None\n",
    "cases_cat = dict()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    global cases_cat\n",
    "#     eventlog = \"wfmpca.csv\"\n",
    "    eventlog = \"bpi2013-pca.csv\"\n",
    "    #eventlog = \"helpdesk.csv\"\n",
    "    columns = (0, 1, 2, 3)\n",
    "    timeformat = \"%Y-%m-%d %H:%M:%S\"\n",
    "    horizon = 8\n",
    "    #eventlog = \"running-example.csv\"\n",
    "    #columns = (3, 0, 7)\n",
    "    #timeformat = \"%Y-%m-%d %H:%M:%S%z\"\n",
    "    cases = loadCases(eventlog, columns, timeformat)\n",
    "    casessets = splitIntoCategories(cases)\n",
    "    \n",
    "    directory = eventlog.replace('.csv', '')\n",
    "    path = '../../results/'+directory+'/horizon_'+str(horizon)\n",
    "    \n",
    "    if os.path.isdir(path) == False:\n",
    "        try:\n",
    "            os.mkdir(path)\n",
    "        except OSError:\n",
    "            print (\"Creation of the directory %s failed\" % path)\n",
    "        else:\n",
    "            print (\"Successfully created the directory %s \" % path)\n",
    "    \n",
    "    for category, cases in casessets.items():\n",
    "        print(\"Predicting remaining time for case category\", category)\n",
    "        runTimePredictions(cases, category, eventlog, directory, horizon)\n",
    "        \n",
    "    print(\"\\nComputing metrics from prediction\")\n",
    "    calcMetrics(cases_cat, directory, horizon)\n",
    "    print(\"\\nMetrics computed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
